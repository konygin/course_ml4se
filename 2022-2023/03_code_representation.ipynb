{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. CODE REPRESENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [x] введение\n",
    "2. [x] AST\n",
    "3. [x] code2vec\n",
    "4. [x] упражнение\n",
    "5. [x] ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Введение\n",
    "\n",
    "*Представление кода* --- это преобразование кода в некоторый математический объект. Какие выдвигаются требования к  этому преобразованию?\n",
    "- важная информация сохраняется\n",
    "- ненужная информация не сохраняется\n",
    "- с результирующим объектом работать проще, чем и с исходным кодом\n",
    "\n",
    "\"Важность\" и \"ненужность\" --- зависит от тех задач, которые предполагается решать. В английском языке используется два термина \"representation\" и \"embedding\". В последнем случае, в качестве математического объекта рассматривается точка метрического пространства (т.е. множество с метрикой).\n",
    "\n",
    "Выбор представления является очень важным шагом, поскольку на этом этапе почти всегда происходит потеря информации. Следовательно,\n",
    "- если теряется важная информация, то это может отрицательно сказаться на качестве решения задачи (вплоть до того, что в задаче классификации классы могут перестать разделяться)\n",
    "- если теряется ненужная информация, то это может пойти задаче на пользу, поскольку уменьшается количество степеней свободы\n",
    "\n",
    "Чаще всего код представляется в виде векторов с вещественными координатами фиксированной размерности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. AST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Abstract syntax tree (AST)* --- абстрактное синтаксическое дерево.\n",
    "\n",
    "В информатике AST --- это конечное помеченное ориентированное дерево, в котором внутренние вершины соответствуют операторам языка программирования, а листья --- операндам (переменные и константы).\n",
    "\n",
    "#### Пример\n",
    "\n",
    "> Алгоритм Евклида и абстрактное синтаксическое дерево:\n",
    ">\n",
    "> [`while b ≠ 0\n",
    "    if a > b\n",
    "        a := a − b\n",
    "    else\n",
    "        b := b − a\n",
    "return a`](#code)\n",
    ">\n",
    "> ![AST](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/Abstract_syntax_tree_for_Euclidean_algorithm.svg/425px-Abstract_syntax_tree_for_Euclidean_algorithm.svg.png)\n",
    "\n",
    "#### Пакет ast\n",
    "\n",
    "https://docs.python.org/3/library/ast.html\n",
    "\n",
    "![ast](./res/03_ast.png)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install astpretty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import astpretty\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = '''\\\n",
    "def f(a, b):\n",
    "    while b != 0:\n",
    "        if a > b:\n",
    "            a = a - b\n",
    "        else:\n",
    "            b = b - a\n",
    "    return a'''\n",
    "tree = ast.parse(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module(\n",
      "    body=[\n",
      "        FunctionDef(\n",
      "            name='f',\n",
      "            args=arguments(\n",
      "                args=[\n",
      "                    arg(arg='a', annotation=None),\n",
      "                    arg(arg='b', annotation=None),\n",
      "                ],\n",
      "                vararg=None,\n",
      "                kwonlyargs=[],\n",
      "                kw_defaults=[],\n",
      "                kwarg=None,\n",
      "                defaults=[],\n",
      "            ),\n",
      "            body=[\n",
      "                While(\n",
      "                    test=Compare(\n",
      "                        left=Name(id='b', ctx=Load()),\n",
      "                        ops=[NotEq()],\n",
      "                        comparators=[Num(n=0)],\n",
      "                    ),\n",
      "                    body=[\n",
      "                        If(\n",
      "                            test=Compare(\n",
      "                                left=Name(id='a', ctx=Load()),\n",
      "                                ops=[Gt()],\n",
      "                                comparators=[Name(id='b', ctx=Load())],\n",
      "                            ),\n",
      "                            body=[\n",
      "                                Assign(\n",
      "                                    targets=[Name(id='a', ctx=Store())],\n",
      "                                    value=BinOp(\n",
      "                                        left=Name(id='a', ctx=Load()),\n",
      "                                        op=Sub(),\n",
      "                                        right=Name(id='b', ctx=Load()),\n",
      "                                    ),\n",
      "                                ),\n",
      "                            ],\n",
      "                            orelse=[\n",
      "                                Assign(\n",
      "                                    targets=[Name(id='b', ctx=Store())],\n",
      "                                    value=BinOp(\n",
      "                                        left=Name(id='b', ctx=Load()),\n",
      "                                        op=Sub(),\n",
      "                                        right=Name(id='a', ctx=Load()),\n",
      "                                    ),\n",
      "                                ),\n",
      "                            ],\n",
      "                        ),\n",
      "                    ],\n",
      "                    orelse=[],\n",
      "                ),\n",
      "                Return(\n",
      "                    value=Name(id='a', ctx=Load()),\n",
      "                ),\n",
      "            ],\n",
      "            decorator_list=[],\n",
      "            returns=None,\n",
      "        ),\n",
      "    ],\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "astpretty.pprint(tree, show_offsets=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Библиотека tree-sitter\n",
    "\n",
    "https://tree-sitter.github.io/tree-sitter/\n",
    "\n",
    "![tree-sitter](./res/03_tree-sitter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. code2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Цель\n",
    "\n",
    "Хотим представить фрагмент кода вектором фиксированной длины. Этот вектор далее хотим использовать для предсказания семантических свойств исходного фрагмента кода.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Идея\n",
    "\n",
    "Решим задачу предсказания имени метода по его исходному коду. В результате обучения модели получим вектора, которые являются хорошим представлением кода."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Статья\n",
    "\n",
    "![](./res/03_code2vec_paper.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обозначения\n",
    "\n",
    "Пусть $C$ --- фрагмент кода. Тогда AST --- это шестёрка $⟨N, T, X, s, δ, φ⟩$, где\n",
    "- $N$ --- множество нетерминальных вершин,\n",
    "- $T$ --- множество терминальных вершин,\n",
    "- $X$ --- множество значений,\n",
    "- $s ∈ N$ --- корневая вершина (корень),\n",
    "- $δ: N → (N \\cup T )^*$ --- функция, которая отображает нетерминальную вершину в список её потомков,\n",
    "- $φ: T → X$ --- функция, которая отображает терминальную вершину в связанную с ней значение.\n",
    "\n",
    "Каждая вершина за исключением корня является потомком ровной одной вершины (отсутствие циклов).\n",
    "\n",
    "*AST-путь* длины $k$ --- это последовательность вида $n_1 d_1 ... n_k d_k n_{k+1}$, где\n",
    "- $n_1$, $n_{k+1} ∈ T$ --- терминальные вершины, а\n",
    "- $n_i ∈ N$ ($i ∈ [2..k]$) --- нетерминальные и\n",
    "- $d_i ∈ \\{↑, ↓\\}$ ($i ∈ [1..k]$) --- направление движения в AST (вверх или вниз).\n",
    "  - если $d_i = ↑$, то $n_i ∈ δ(n_{i+1})$\n",
    "  - если $d_i = ↓$, то $n_{i+1} ∈ δ(n_i)$\n",
    "\n",
    "Для AST-пути $p$ положим $start(p) := n_1$ и $end(p) := n_{k+1}$.\n",
    "\n",
    "Пусть $p$ --- AST-путь, тогда *контекстный путь* --- это тройка $⟨x_s, p, x_t⟩$, где\n",
    "- $x_s = φ(start(p))$\n",
    "- $x_t = φ(end(p))$\n",
    "\n",
    "т.е. значения, связанные с начальной и конечной вершинами пути $p$ (или контекст пути).\n",
    "\n",
    "#### Пример\n",
    "\n",
    "> Для выражения `x = 7;` имеем такой пример контекстного пути\n",
    "> $$⟨x, (NameExpr ↑ AssignExpr ↓ IntegerLiteralExpr), 7 ⟩.$$\n",
    "\n",
    "Пусть $C$ --- фрагмент кода и $⟨N, T, X, s, δ, φ⟩$ --- соответствующее AST-дерево. Через $TPairs$ обозначим множество всех пар различных терминальных вершин, то есть\n",
    "$$ TPairs(C) = \\{(term_i , term_j) | term_i, term_j ∈ termNodes(C) ∧ i \\neq j\\},$$\n",
    "где $termNodes$ --- множество всех терминальных вершин для фрагмента кода $C$.\n",
    "\n",
    "Положим\n",
    "$$ Rep(C) = \\{ (x_s , p, x_t )| ∃(term_s, term_t) ∈ TPairs(C): x_s = φ(term_s) ∧ x_t = φ(term_t) ∧ start(p) = term_s ∧ end(p) = term_t\\}.$$\n",
    "Таким образом, по фрагменту кода $C$ определяется множество всех контекстных путей вида $⟨x_s, p, x_t⟩$,\n",
    " где $p$ --- путь в соответствующем AST.\n",
    " \n",
    "#### Пример\n",
    "\n",
    "> `\n",
    "boolean f(Object target) {\n",
    "    for (Object elem: this.elements){\n",
    "        if (elem.equals(target)) {\n",
    "            return true;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "`\n",
    ">\n",
    "> ![ast](./res/03_code2vec_ast.png)\n",
    "> Эллипсы --- терминальные и нетерминальные вершины, прямоугольники --- значения.\n",
    ">\n",
    "> Контекстный путь 1:\n",
    ">$$(elements, Name ↑ FieldAccess ↑ Foreach ↓ Block ↓ IfStmt ↓ Block ↓ Return ↓ BooleanExpr, true).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель\n",
    "\n",
    "Модель имеет следующую архитектуру\n",
    "\n",
    "![overview](./res/03_code2vec_overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Контекстный вектор\n",
    "\n",
    "Модель использует два (обучаемых) словаря для построения эмбеддингов:\n",
    "- $path\\_vocab$ и\n",
    "- $value\\_vocab$.\n",
    "\n",
    "Словари реализуются матрицами, в которых каждой строке соответствует путь ($path\\_vocab$) или значение ($value\\_vocab$). Имеем\n",
    "$$path\\_vocab  \\in R^{|P| \\times d},$$\n",
    "$$value\\_vocab \\in R^{|X| \\times d},$$\n",
    "\n",
    "где $X$ --- множество значений для терминальных вершин AST-дерева, которые мы имеем на этапе обучения,\n",
    "а $P$ --- множество всех AST-путей.\n",
    "Чтобы ограничить размер данных для обучения и уменьшить разреженность данные, можно ограничить различные параметры путей (например, максимальная длина пути $k$). Эти значения определяются эмпирически как гиперпараметры модели.\n",
    "\n",
    "Эмбеддинги получаются выбором соответствующей строки матрицы.\n",
    "\n",
    "Например, $value\\_vocab$ содержит строки для каждого из значений `boolean`, `target` и `Object`.\n",
    "А $path\\_vocab$ содержит строки, который соответствуют каждому из AST-путей (без учёта значений), например, крвсный путь 1 это:\n",
    "$$ Name ↑ FieldAccess ↑ Foreach ↓ Block ↓ IfStmt ↓ Block ↓ Return ↓ BooleanExpr.$$\n",
    "\n",
    "Значения этих матриц инициализируются случайным образом. Матрицы обучаются, одновременно с сетью.\n",
    "\n",
    "Размерность $d$ определяется эмпирически, ограничено временем обучения, сложностью модели и GPU-памятью и обычно находится в диапазоне от 100 до 500. Для удобства, эмбеддинги путей и значений будут иметь одинаковый размер $d$, но в общем случае могу отличаться. \n",
    "\n",
    "Через $B = \\{b_1 , ..., b_n\\}$ обозначим множество контекстных путей, которые были извлечены из фрагмента кода.\n",
    "Множество $B$ используется для обучения модели.\n",
    "\n",
    "Пусть $b_i = ⟨x_s, p_j, x_t⟩$ --- один из контекстных путей, при этом ${x_s, x_t} \\in X$ --- значения терминальных вершин и $p_j \\in P$ --- соединяющий их путь. Каждый компонент контекстного пути через матрицы превращается в соответствующий эмбеддинг. Три этих эмбеддинга каждого контекстного пути конкатенируются в единый *контекстный вектор (context vector)*: $c_i ∈ R^{3d}$. Этот контекстный вектор является представлением контекстного пути:\n",
    "$$c_i = embedding(⟨x_s, p_j, x_t⟩) = [value\\_vocab_s; path\\_vocab_j; value\\_vocab_t] ∈ R^{3d}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Полносвязный вектор\n",
    "\n",
    "Поскольку каждый контекстный вектор $c_i$ получается конкатенацией трёх независимых векторов, было бы неплохо их \"перемешать\". Это делает полносвязный слой.\n",
    "\n",
    "\"Перемешивание\" осуществляется раздельно для каждого контекстного вектора, но используется один и тот же слой. \n",
    "\n",
    "Через $c̃_i$ обозначается выход полносвязного слоя:\n",
    "$$c̃_i = tanh(W c_i),$$\n",
    "где $W \\in R^{d \\times 3d}$ --- обучаемая матрица весов.\n",
    "\n",
    "Высота матрицы весов $W$ определяет размерность вектора $c̃_i$ и для удобства имеет тот же размер ($d$), как и раньше. В общем случае высота $W$ может быть разной; это повлияет на размер конечного *кодового вектора (code vector)*. Таким образом полносвязный слой сжимает контекстный вектор размера $3d$ в комбинированный контекстный вектор размера $d$ (combined context vectors), умножая его на матрицу весов, а затем применяет функцию $tanh$ к каждому элементу вектора отдельно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention\n",
    "\n",
    "Attention-механизм вычисляет средневзвешенное значение по комбинированным контекстным векторам (combined context vectors), и его основная задача состоит в вычислении скалярного веса для каждого из них. Attention-вектор $a \\in R^d$ инициализируется случайным образом и обучается одновременно с сетью. Для заданных комбинированных контекстных векторов (combined context vectors) $\\{c̃_1, ..., c̃_n\\}$, вес $α_i$ каждого $c̃_i$ вычисляется как нормализованное скалярное произведение между комбинированным контекстным вектором (combined context vectors) и глобальным attention-вектором $a $:\n",
    "$$attention-вес~ α_i = \\frac{exp(c̃_i^T a)}{\\sum_{j=1}^{n}exp(c̃_j^T a)}.$$\n",
    "\n",
    "Экспоненты используются только для того, чтобы сделать attention-веса положительными, и они делятся на суммы, чтобы получить значение было от $0$ до $1$ (как в случае softmax).\n",
    "Агрегированный кодовый вектор (code vector) $v \\in R^d$, представляющий весь фрагмент кода, представляет собой линейную комбинацию комбинированных контекстных векторов (combined context vectors) $\\{c̃_1, ..., c̃_n\\}$ с attention-весами:\n",
    "$$кодовый~ вектор~ (code~ vector)~ v = \\sum_{i=1}^n α_i c̃_i.$$\n",
    "\n",
    "Таким образом, attention-веса неотрицательны, их сумма равна $1$ и они используются как коэффициенты комбинированных контекстных векторов (combined context vectors) $c̃_i$. Поэтому attention-механизм можно рассматривать как взвешенное усреднение, при котором веса обучаются и рассчитываются по отношению к другим элементам из множества контекстных путей (path-contexts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение\n",
    "\n",
    "Прогноз целевой метки (tag) выполняется с использованием кодового вектора (code vector). Для этого необходим словать целевых меток (tag), который обучается одновременно с сетью:\n",
    "$$tags\\_vocab ∈ R^{|Y| \\times d},$$\n",
    "где $Y$ --- набор значений целевых меток (tag), собранных из обучающей выборки. Как и раньше, эмбеддинг $tag_i$ --- это $i$-ая строка таблицы $tags\\_vocab$. Например, $tags\\_vocab$ содержит строки для каждой из целевых меток `contains`, `matches` и `canHandle`. Итоговое распределение модели $q(y)$ вычисляется как скалярное произведение (нормализованное по softmax) между кодовым вектором (code vector) $v$ и каждым из эмбеддингов целевых метрик:\n",
    "$$for~ y_i \\in Y: q(y_i) = \\frac{exp(v^T tags\\_vocab_i)}{\\sum_{j} exp(v^T tags\\_vocab_j)}.$$\n",
    "\n",
    "\n",
    "В целом, следующие компоненты модели проходят обучение:\n",
    "- эмбеддинги для путей и значений (матрицы $path\\_vocab$ и $value\\_vocab$)\n",
    "- полносвязный слой (матрица $W$)\n",
    "- attention-вектор ($a$)\n",
    "- эмбеддинги для целевых меток ($tags\\_vocab$).\n",
    "\n",
    "\n",
    "При обучении в качестве функции потерь выступает кросс-энтропия между предсказанным распределением $q$ и истинным распределением $p$ (значение $1$ фактической метке в обучающем примере и $0$ в противном случае).\n",
    "\n",
    "Сеть обучается с использованием любого алгоритма, основанного на градиентном спуске, и стандартного подхода обратного распространения ошибки обучения по каждому из обучаемых параметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация\n",
    "\n",
    "- https://code2vec.org/\n",
    "- https://github.com/bentrevett/code2vec\n",
    "- https://github.com/d6ms/pytorch-code2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Упражение\n",
    "\n",
    "Используя готовую реализацию code2vec, исследовать свойства такого представления кода.\n",
    "1. Буду ли близким вектора, соответствующие семантически близким фрагментам кода?\n",
    "2. Какую меру близости лучше всего использовать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Полезные ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [AST](https://en.wikipedia.org/wiki/Abstract_syntax_tree)\n",
    "- Alon et al --- Code2Vec: Learning distributed representations of code, 2019\n",
    "  * [paper](https://arxiv.org/abs/1803.09473)\n",
    "  * [DOI](https://doi.org/10.1145/3290353)\n",
    "  * [presentation @ FLOC'18](https://www.youtube.com/watch?v=ya74zYDhSnM)\n",
    "  * [presentation @ POPL'19](https://www.youtube.com/watch?v=EJ8okcxL2Iw)\n",
    "  * [paper reading](https://www.youtube.com/watch?v=4j8mif-ybyw)\n",
    "  * [demo](https://code2vec.org/)\n",
    "  * [source code](https://github.com/tech-srl/code2vec)\n",
    "  * [more code](https://github.com/sonoisa/code2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
