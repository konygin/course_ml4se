{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. CODE GENERATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [x] введение\n",
    "2. [x] [Codex](https://openai.com/blog/openai-codex/)\n",
    "3. [x] [AlphaCode](https://www.deepmind.com/blog/competitive-programming-with-alphacode)\n",
    "5. [x] упражение\n",
    "6. [x] ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model       | Company      | Date |  Model |\n",
    "|-------------| -------------| -----|-----|\n",
    "| [GPT-J](https://6b.eleuther.ai/)       | Eleuther.ai  | 2021 | https://github.com/kingoflolz/mesh-transformer-jax/#gpt-j-6b |\n",
    "| [GPT-Neo](https://huggingface.co/EleutherAI/gpt-neo-2.7B)    | Eleuther.ai  | 2021 | https://github.com/EleutherAI/gpt-neo |\n",
    "| [GPT-NeoX](https://huggingface.co/docs/transformers/model_doc/gpt_neox)| Eleuther.ai  | 2021 | https://github.com/EleutherAI/gpt-neox |\n",
    "| [Codex](https://openai.com/blog/openai-codex/)       | OpenAI | 2021 | - |\n",
    "| [CodeT5](https://blog.salesforceairesearch.com/codet5/)      | Salesforce   | 2021 | https://github.com/salesforce/CodeT5 |\n",
    "| [CodeParrot](https://github.com/huggingface/transformers/tree/master/examples/research_projects/codeparrot)  | Hugging Face | 2021 | https://huggingface.co/lvwerra/codeparrot |\n",
    "| [AlphaCode](https://www.deepmind.com/blog/competitive-programming-with-alphacode)   | Deepmind  | 2022 | - |\n",
    "| [InCoder](https://sites.google.com/view/incoder-code-models) | Meta | 2022 | https://github.com/dpfried/incoder/blob/main/README.md |\n",
    "| [CodeWhisperer](https://aws.amazon.com/codewhisperer/) | Amazon | 2022 | - |\n",
    "| [CodeGen](https://arxiv.org/abs/2203.13474) | Salesforce | 2022 | https://github.com/salesforce/CodeGen |\n",
    "| [PanGu-Coder](https://arxiv.org/abs/207.11280) | Huawei | 2022 | - |\n",
    "| [PaLM-Coder](https://arxiv.org/abs/2204.02311) | Google | 2022 | - |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CodeParrot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline('text-generation', model='lvwerra/codeparrot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'def add_numbers(a, b):\\n    \"\"\"add two numbers\"\"\"'\n",
    "code = pipe(text)[0]['generated_text']\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InCoder\n",
    "\n",
    "- https://huggingface.co/spaces/facebook/incoder-demo\n",
    "- https://huggingface.co/facebook/incoder-6B\n",
    "- https://github.com/dpfried/incoder\n",
    "- https://github.com/dpfried/incoder/blob/main/example_usage.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Codex\n",
    "\n",
    "\n",
    "![](./res/05_codex_paper.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codex ([OpenAI](https://openai.com/), 2021) --- это языковая модель [GPT](https://openai.com/blog/language-unsupervised/), зафайнтюненная (fine-tuned) на общедоступном коде из GitHub (Python). На одной из версий этой модели построен [GitHub Copilot](https://copilot.github.com/) (Visual Studio Code, Visual Studio, Neovim и JetBrains IDE).\n",
    "\n",
    "![](https://nira.com/wp-content/uploads/2021/11/image4-1-620x308.png)\n",
    "\n",
    "Кроме модели Codex в той же статье был предложен датасет [HumanEval](https://github.com/openai/human-eval) --- составленный вручную датасет для оценки моделей генерации кода.\n",
    "\n",
    "Поскольку входом для модели генерации кода служит текст (описание задачи) на естественном языке, то кажется естественным строить модель на основе файнтюнинга (fine-tuning) семейства моделей [GPT-3](https://arxiv.org/abs/2005.14165), которые уже имеют представление об естественном языке. Кстати, модель GPT-3 до файнтюнинга уже могла генерировать простые программы на языке Python из docstring-ов.\n",
    "\n",
    "Из-за большого размера данных для fine-tuning-а выигрыша в качестве от дообучения предобученной модели нет. Но поскольку предобученная модель сходится быстрее, использовались предобученные модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные для обучения\n",
    "\n",
    "1. 54 миллионов общедоступных репозиториев с GitHub-а\n",
    "2. 179 ГБ уникальных файлов Python размером менее 1 МБ\n",
    "3. отфильтрованы файлы, которые имели среднюю длину строки более 100, максимальную длину строки более 1000 или содержали небольшой процент буквенно-цифровых символов (вероятно, были созданы автоматически)\n",
    "4. окончательный набор данных --- 159 ГБ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение\n",
    "\n",
    "Обучение состоит в файнтюнинге предобученной модели GPT-3.\n",
    "![](https://jalammar.github.io/images/gpt3/04-gpt3-generate-tokens-output.gif)\n",
    "\n",
    "- скорость обучения (learning rate) --- такая же, как при обучении соответствующей GPT\n",
    "- 175 шагов линейного разогрева (warmup, линейный рост скорости обучения в начале)\n",
    "- косинусное затуханием скорости обучения\n",
    "- 100 миллиардов токенов\n",
    "- оптимизатор Adam с $\\beta_1 = 0.9$, $\\beta_2 = 0.95$, $\\epsilon = 10^{-8}$\n",
    "- коэффициент снижения (weight decay) веса $0.1$ (добавяем слагаемое с коэффициентом в функцию потерь и поощряем меньше веса: $L_{new}(w) = L_{original}(w) + \\lambda w^Tw$).\n",
    "\n",
    "Для того, чтобы максимально использовать текстовые представления из GPT, авторы делали лексический анализ кода на основе токенизатора GPT-3 (BPE).\n",
    "Поскольку распределение слов в коде GitHub отличается от распределения в обычном тексте, этот токенизатор не очень эффективен для код.\n",
    "Самый большой источник неэффективности возникает из-за кодирования пробелов, поэтому авторы добавили дополнительный набор токенов для представления пробелов разной длины.\n",
    "Это позволило сократить количество токенов примерно на 30%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование (evaluation)\n",
    "\n",
    "Для тестирования был разработан набор задач по программированию HumanEval.\n",
    "- 164 задачи\n",
    "- задача: сигнатура функции, строка документации, тело и несколько тестов (в среднем, 7.7 тестов на задачу)\n",
    "- задачи написаны заново, чтобы не было пересечения с GitHub: например, существует более десяти общедоступных репозиториев, содержащих решения задач [Codeforces](https://codeforces.com/)\n",
    "- задачи программирования в наборе данных HumanEval оценивают понимание языка, рассуждения, алгоритмы и простую математику\n",
    "- доступны: https://github.com/openai/human-eval\n",
    "\n",
    "Оценивалась функциональная правильность с помощью метрики `pass@k`:\n",
    "> для каждой задачи генерируется $k$ образцов кода, задача считается решенной, если какой-либо образец проходит тесты, и указывается общая доля решенных проблем.\n",
    "\n",
    "Чтобы вычислить `pass@k', преобразуем каждую задачу HumanEval в prompt, состоящий из заголовка, сигнатуры и строки документации.\n",
    "\n",
    "Prompt, отправляемый в  модель, отображается на белом фоне, а успешный код, созданный моделью, отображается на желтом фоне.\n",
    "\n",
    "![Prompt](https://production-media.paperswithcode.com/datasets/a2af6cf1-212b-4a05-8d5c-55170a21ce05.png)\n",
    "\n",
    "Конец генерации --- берем токены из Codex, пока не встретим одну из следующих стоп-последовательностей:\n",
    "- `\\nclass`\n",
    "- `\\ndef`\n",
    "- `\\n#`\n",
    "- `\\nif` или\n",
    "- `\\nprint`,\n",
    "\n",
    "поскольку в противном случае модель продолжаит генерировать дополнительные функции или операторы.\n",
    "Использовалось *nucleus sampling* со значением $p = 0.95$ (*top p sampling*, берём все варианты, которые в сумме дают вероятность $p$).\n",
    "\n",
    "![Evaluation](./res/05_codex_table.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. AlphaCode\n",
    "\n",
    "\n",
    "![](./res/05_alphacode_paper.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несмотря на достижения в области решении задач с помощью машинного обучения, подходы ограничивались относительно простыми задачами по математике и программированию, или поиском и копированием существующих решений.\n",
    "\n",
    "Одна из задач AlphaCode --- создавать компьютерные программы на конкурентоспособном уровне. Во время тестирования AlphaCode вошла в число 54% лучших участников соревнований по программированию, решая новые задачи, требующие сочетания критического мышления, логики, алгоритмов, кодирования и понимания естественного языка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример\n",
    "\n",
    "![Example](https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2022/02/DeepMind-AlphaCode-visualization.png?ssl=1)\n",
    "\n",
    "\n",
    "Ещё примеры:\n",
    "- https://alphacode.deepmind.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные\n",
    "\n",
    "### Pre-training dataset\n",
    "\n",
    "- срез некоторых публичных репозиториев GitHub, взятых на 2021-07-14\n",
    "- языки программирования: C++, C#, Go, Java, JavaScript, Lua, PHP, Python, Ruby, Rust, Scala и TypeScript\n",
    "- исключены все файлы размером более 1 МБ или со строками длиннее 1000 символов (автогенерация)\n",
    "- исключены дубликаты, игнорируя пробелы при сравнении\n",
    "\n",
    "Получилось 715 ГБ кода\n",
    "\n",
    "### CodeContests fine-tuning dataset\n",
    "\n",
    "Был создан датасет CodeContests:\n",
    "- задачи\n",
    "- решения\n",
    "- тесты\n",
    "\n",
    "Данные были извлечены с платформы [Codeforces](https://codeforces.com/) + [Description2Code](https://github.com/ethancaballero/description2code) + [CodeNet](https://github.com/IBM/Project_CodeNet).\n",
    "\n",
    "Validation- и test-части --- это новые задачи из Codeforces. Разделение на основе времени.\n",
    "\n",
    "![Dataset](./res/05_alphacode_dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подход\n",
    "\n",
    "![Overview](./res/05_alphacode_overview.png)\n",
    "\n",
    "1. Предобучаем языковую модель на основе транформеров, используя код GitHub\n",
    "2. Файнтюним модель на данных с соревнований\n",
    "3. При решении каждой задачи генерируется большое количество решений\n",
    "4. Фильтрация решений. Получаем небольшой набор решений, которые отправляем на проверку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель\n",
    "\n",
    "- трансформер, энкодер-декодерная архитектура\n",
    "- асимметричная архитектура с 1536 токенов для энкодера и 768 токенов для декодера: описание задачи в среднем в два раза длиннее человеческого решения\n",
    "- неглубокий энкодер и глубокий декодер\n",
    "- [SentencePiece](https://github.com/google/sentencepiece) в качестве токенизатора (общий для энкодера и декодера), словарь содержал 8000 токенов\n",
    "\n",
    "![Parameters](./res/05_alphacode_params.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация\n",
    "\n",
    "### Large scale sampling\n",
    "\n",
    "- генерировать половину решений на Python и половину на C++\n",
    "- случайно накидывать тэги и уровни сложности для задач в качестве natural language prompt\n",
    "- использовать относительно высокую температуру при генерации\n",
    "\n",
    "В итоге имеем миллионы решения для одной задачи\n",
    "\n",
    "\n",
    "### Filtering\n",
    "\n",
    "Обычно на соревнованиях количество попыток ограничено. Здесь ограничение -- 10 попыток. Поэтому используются тесты из задачи для фильтрации. Так фильтрируется около 99% решений. Примерно для 10% задая не находится решений, которые бы прошли тесты.\n",
    "\n",
    "### Clustering\n",
    "\n",
    "- генерируются новые тестовые данные\n",
    "- решения объединяются в кластеры по ответам на этих тестовых данных\n",
    "- из каждого кластера, начиная с самого большого, выбираются представители\n",
    "\n",
    "Для генерации тестовых данных используется отдельная небольшая специально обученная модель\n",
    "\n",
    "### Результаты\n",
    "\n",
    "![Results](./res/05_alphacode_results.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Упражнение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Провести эксперимент с генерацей кода с помощью модели InCoder. Исследовать влияние описания задачи, наличия юнит-тестов и т.д. на качество сгенерированного кода."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Полезные ссылки\n",
    "\n",
    "- https://github.com/saltudelft/ml4se#code-generation\n",
    "- [GPT-3](https://jalammar.github.io/how-gpt3-works-visualizations-animations/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
