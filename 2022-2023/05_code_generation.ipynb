{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. CODE GENERATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [x] введение\n",
    "2. [x] [Codex](https://openai.com/blog/openai-codex/)\n",
    "3. [x] [AlphaCode](https://www.deepmind.com/blog/competitive-programming-with-alphacode)\n",
    "5. [x] упражение\n",
    "6. [x] ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model       | Company      | Date |  Model |\n",
    "|-------------| -------------| -----|-----|\n",
    "| [GPT-J](https://6b.eleuther.ai/)       | Eleuther.ai  | 2021 | https://github.com/kingoflolz/mesh-transformer-jax/#gpt-j-6b |\n",
    "| [GPT-Neo](https://huggingface.co/EleutherAI/gpt-neo-2.7B)    | Eleuther.ai  | 2021 | https://github.com/EleutherAI/gpt-neo |\n",
    "| [GPT-NeoX](https://huggingface.co/docs/transformers/model_doc/gpt_neox)| Eleuther.ai  | 2021 | https://github.com/EleutherAI/gpt-neox |\n",
    "| [Codex](https://openai.com/blog/openai-codex/)       | OpenAI | 2021 | - |\n",
    "| [CodeT5](https://blog.salesforceairesearch.com/codet5/)      | Salesforce   | 2021 | https://github.com/salesforce/CodeT5 |\n",
    "| [CodeParrot](https://github.com/huggingface/transformers/tree/master/examples/research_projects/codeparrot)  | Hugging Face | 2021 | https://huggingface.co/lvwerra/codeparrot |\n",
    "| [AlphaCode](https://www.deepmind.com/blog/competitive-programming-with-alphacode)   | Deepmind  | 2022 | - |\n",
    "| [InCoder](https://sites.google.com/view/incoder-code-models) | Meta | 2022 | https://github.com/dpfried/incoder/blob/main/README.md |\n",
    "| [CodeWhisperer](https://aws.amazon.com/codewhisperer/) | Amazon | 2022 | - |\n",
    "| [CodeGen](https://arxiv.org/abs/2203.13474) | Salesforce | 2022 | https://github.com/salesforce/CodeGen |\n",
    "| [PanGu-Coder](https://arxiv.org/abs/207.11280) | Huawei | 2022 | - |\n",
    "| [PaLM-Coder](https://arxiv.org/abs/2204.02311) | Google | 2022 | - |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CodeParrot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CodeParrot\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline('text-generation', model='lvwerra/codeparrot')\n",
    "#pipe('def hello_world():')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'def add_numbers(a, b):\\n    \"\"\"add two numbers\"\"\"'\n",
    "\n",
    "code = pipe(text)[0]['generated_text']\n",
    "\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InCoder\n",
    "\n",
    "- https://huggingface.co/spaces/facebook/incoder-demo\n",
    "- https://huggingface.co/facebook/incoder-6B\n",
    "- https://github.com/dpfried/incoder\n",
    "- https://github.com/dpfried/incoder/blob/main/example_usage.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Codex\n",
    "\n",
    "\n",
    "![](./res/05_codex_paper.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codex ([OpenAI](https://openai.com/), 2021) --- это языковая модель [GPT](https://openai.com/blog/language-unsupervised/), зафайнтюненная (fine-tuned) на общедоступном коде из GitHub (Python). На одной из версий этой модели построен [GitHub Copilot](https://copilot.github.com/) (Visual Studio Code, Visual Studio, Neovim и JetBrains IDE).\n",
    "\n",
    "![](https://nira.com/wp-content/uploads/2021/11/image4-1-620x308.png)\n",
    "\n",
    "Кроме модели Codex в той же статье был предложен датасет [HumanEval](https://github.com/openai/human-eval) --- составленный вручную датасет для оценки моделей генерации кода.\n",
    "\n",
    "Поскольку входом для модели генерации кода служит текст (описание задачи) на естественном языке, то кажется естественным строить модель на основе файнтюнинга (fine-tuning) семейства моделей [GPT-3](https://arxiv.org/abs/2005.14165), которые уже имеют представление об естественном языке. Кстати, модель GPT-3 до файнтюнинга уже могла генерировать простые программы на языке Python из docstring-ов.\n",
    "\n",
    "Из-за большого размера данных для fine-tuning-а выигрыша в качестве от дообучения предобученной модели нет. Но поскольку предобученная модель сходится быстрее, использовались предобученные модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные для обучения\n",
    "\n",
    "1. 54 миллионов общедоступных репозиториев с GitHub-а\n",
    "2. 179 ГБ уникальных файлов Python размером менее 1 МБ\n",
    "3. отфильтрованы файлы, которые имели среднюю длину строки более 100, максимальную длину строки более 1000 или содержали небольшой процент буквенно-цифровых символов (вероятно, были созданы автоматически)\n",
    "4. окончательный набор данных --- 159 ГБ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение\n",
    "\n",
    "Обучение состоит в файнтюнинге предобученной модели GPT-3.\n",
    "![](https://jalammar.github.io/images/gpt3/04-gpt3-generate-tokens-output.gif)\n",
    "\n",
    "- скорость обучения (learning rate) --- такая же, как при обучении соответствующей GPT\n",
    "- 175 шагов линейного разогрева (warmup, линейный рост скорости обучения в начале)\n",
    "- косинусное затуханием скорости обучения\n",
    "- 100 миллиардов токенов\n",
    "- оптимизатор Adam с $\\beta_1 = 0.9$, $\\beta_2 = 0.95$, $\\epsilon = 10^{-8}$\n",
    "- коэффициент снижения (weight decay) веса $0.1$ (добавяем слагаемое с коэффициентом в функцию потерь и поощряем меньше веса: $L_{new}(w) = L_{original}(w) + \\lambda w^Tw$).\n",
    "\n",
    "Для того, чтобы максимально использовать текстовые представления из GPT, авторы делали лексический анализ кода на основе токенизатора GPT-3 (BPE).\n",
    "Поскольку распределение слов в коде GitHub отличается от распределения в обычном тексте, этот токенизатор не очень эффективен для код.\n",
    "Самый большой источник неэффективности возникает из-за кодирования пробелов, поэтому авторы добавили дополнительный набор токенов для представления пробелов разной длины.\n",
    "Это позволило сократить количество токенов примерно на 30%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование (evaluation)\n",
    "\n",
    "Для тестирования был разработан набор задач по программированию HumanEval.\n",
    "- 164 задачи\n",
    "- задача: сигнатура функции, строка документации, тело и несколько тестов (в среднем, 7.7 тестов на задачу)\n",
    "- задачи написаны заново, чтобы не было пересечения с GitHub: например, существует более десяти общедоступных репозиториев, содержащих решения задач [Codeforces](https://codeforces.com/)\n",
    "- задачи программирования в наборе данных HumanEval оценивают понимание языка, рассуждения, алгоритмы и простую математику\n",
    "- доступны: https://github.com/openai/human-eval\n",
    "\n",
    "Оценивалась функциональная правильность с помощью метрики `pass@k`:\n",
    "> для каждой задачи генерируется $k$ образцов кода, задача считается решенной, если какой-либо образец проходит тесты, и указывается общая доля решенных проблем.\n",
    "\n",
    "Чтобы вычислить `pass@k', преобразуем каждую задачу HumanEval в prompt, состоящий из заголовка, сигнатуры и строки документации.\n",
    "\n",
    "Prompt, отправляемый в  модель, отображается на белом фоне, а успешный код, созданный моделью, отображается на желтом фоне.\n",
    "\n",
    "![Prompt](https://production-media.paperswithcode.com/datasets/a2af6cf1-212b-4a05-8d5c-55170a21ce05.png)\n",
    "\n",
    "Конец генерации --- берем токены из Codex, пока не встретим одну из следующих стоп-последовательностей:\n",
    "- `\\nclass`\n",
    "- `\\ndef`\n",
    "- `\\n#`\n",
    "- `\\nif` или\n",
    "- `\\nprint`,\n",
    "\n",
    "поскольку в противном случае модель продолжаит генерировать дополнительные функции или операторы.\n",
    "Использовалось *nucleus sampling* со значением $p = 0.95$ (*top p sampling*, берём все варианты, которые в сумме дают вероятность $p$).\n",
    "\n",
    "![Evaluation](./res/05_codex_table.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. AlphaCode\n",
    "\n",
    "\n",
    "![](./res/05_alphacode_paper.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несмотря на достижения в области решении задач с помощью машинного обучения, подходы ограничивались относительно простыми задачами по математике и программированию, или поиском и копированием существующих решений.\n",
    "\n",
    "Одна из задач AlphaCode --- создавать компьютерные программы на конкурентоспособном уровне. Во время тестирования AlphaCode вошла в число 54% лучших участников соревнований по программированию, решая новые задачи, требующие сочетания критического мышления, логики, алгоритмов, кодирования и понимания естественного языка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример\n",
    "\n",
    "![Example](https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2022/02/DeepMind-AlphaCode-visualization.png?ssl=1)\n",
    "\n",
    "\n",
    "Ещё примеры:\n",
    "- https://alphacode.deepmind.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные\n",
    "\n",
    "### Pre-training dataset\n",
    "\n",
    "- срез некоторых публичных репозиториев GitHub, взятых на 2021-07-14\n",
    "- языки программирования: C++, C#, Go, Java, JavaScript, Lua, PHP, Python, Ruby, Rust, Scala и TypeScript\n",
    "- исключены все файлы размером более 1 МБ или со строками длиннее 1000 символов (автогенерация)\n",
    "- исключены дубликаты, игнорируя пробелы при сравнении\n",
    "\n",
    "Получилось 715 ГБ кода\n",
    "\n",
    "### CodeContests fine-tuning dataset\n",
    "\n",
    "Был создан датасет CodeContests:\n",
    "- задачи\n",
    "- решения\n",
    "- тесты\n",
    "\n",
    "Данные были извлечены с платформы [Codeforces](https://codeforces.com/) + [Description2Code](https://github.com/ethancaballero/description2code) + [CodeNet](https://github.com/IBM/Project_CodeNet).\n",
    "\n",
    "Validation- и test-части --- это новые задачи из Codeforces. Разделение на основе времени.\n",
    "\n",
    "![Dataset](./res/05_alphacode_dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подход\n",
    "\n",
    "![Overview](./res/05_alphacode_overview.png)\n",
    "\n",
    "1. Предобучаем языковую модель на основе транформеров, используя код GitHub\n",
    "2. Файнтюним модель на данных с соревнований\n",
    "3. При решении каждой задачи генерируется большое количество решений\n",
    "4. Фильтрация решений. Получаем небольшой набор решений, которые отправляем на проверку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель\n",
    "\n",
    "- трансформер, энкодер-декодерная архитектура\n",
    "- асимметричная архитектура с 1536 токенов для энкодера и 768 токенов для декодера: описание задачи в среднем в два раза длиннее человеческого решения\n",
    "- неглубокий энкодер и глубокий декодер\n",
    "- [SentencePiece](https://github.com/google/sentencepiece) в качестве токенизатора (общий для энкодера и декодера), словарь содержал 8000 токенов\n",
    "\n",
    "![Parameters](./res/05_alphacode_params.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение\n",
    "\n",
    "### Pre-training\n",
    "\n",
    "- GitHub dataset\n",
    "- standard cross-entropy next-token prediction loss for the decoder\n",
    "- masked language modeling loss for the encoder\n",
    "- base 1B parameter model was trained for 106 steps with a batch size of 256\n",
    "- AdamW (Loshchilov and Hutter, 2017), $\\beta_1 = 0.9$, $\\beta_2 = 0.999$ for {300M, 1B, 3B} models, and $\\beta_2 = 0.95$ for {9B, 41B} models\n",
    "- weight decay of 0.1 to enhance regularization\n",
    "- initial learning rate of $10^{−4}$, which was then cosine decayed to $10^{-5}$ at the end of pre-training\n",
    "- linearly warmed-up the learning rate from $10^{−9}$ to $10^{−4}$ over the first 1000 training steps\n",
    "- clipped the global gradient norm to stay below 1.0\n",
    "\n",
    "### Fine-tuning\n",
    "\n",
    "- CodeContests dataset\n",
    "- natural language problem description for the encoder and the program solution for the decoder\n",
    "- used both the standard next-token prediction and masked language modeling losses\n",
    "- initial learning rate as $10^{−5}$, and cosine decayed it to $10^{−6}$ at the end of fine-tuning\n",
    "- used the same linear warm-up stage for the learning rate over the first 1000 training steps\n",
    "\n",
    "ALSO:\n",
    "\n",
    "- Tempering\n",
    "- *Value conditioning & prediction*. CodeContests contains both correct and incorrect problem submissions. We used value conditioning and prediction to discriminate between these two types of submissions, providing an additional training signal and allowing use of data which could otherwise mislead the model. Similar approaches were used in, e.g., Vinyals et al. (2019). In value conditioning, we inserted whether or not a submission was correct into the problem description so that the model can condition on this information, as shown in Figure 5. At sampling time, the model was always conditioned on the sample being correct. In value prediction, we added an auxiliary value prediction task during training such that the last layer token representations before projecting to logits are also used in a small Transformer to classify whether the submission is correct. Value prediction was not used during sampling\n",
    "- *GOLD* (Pang and He, 2020). Solving competitive programming problems from descriptions is inherently a one-of-many task (Nandwani et al., 2021): each unique problem allows many distinct solutions that depend on algorithm choice, implementation, etc. CodeContests contains several orders of magnitude more solutions than descriptions (Table 1). Standard maximum likelihood objectives minimise loss by putting some weight on each solution in the training set (like recall), whereas our metric measures whether a model can find a single correct solution in the submission attempt budget (like precision). To resolve this discrepancy, we adopted a variation of GOLD (Pang and He, 2020), an offline RL algorithm which allows the model to both learn from tokens it already assigns high likelihood to, and to ignore tokens that are not in its distribution (allowing it to concentrate on precision). To combine GOLD and tempering, we introduce a short training phase between pretraining and finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация\n",
    "\n",
    "### Large scale sampling\n",
    "\n",
    "- генерировать половину решений на Python и половину на C++\n",
    "- случайно накидывать тэги и уровни сложности для задач в качестве natural language prompt\n",
    "- использовать относительно высокую температуру при генерации\n",
    "\n",
    "В итоге имеем миллионы решения для одной задачи\n",
    "\n",
    "\n",
    "### Filtering\n",
    "\n",
    "Обычно на соревнованиях количество попыток ограничено. Здесь ограничение -- 10 попыток. Поэтому используются тесты из задачи для фильтрации. Так фильтрируется около 99% решений. Примерно для 10% задая не находится решений, которые бы прошли тесты.\n",
    "\n",
    "### Clustering\n",
    "\n",
    "- генерируются новые тестовые данные\n",
    "- решения объединяются в кластеры по ответам на этих тестовых данных\n",
    "- из каждого кластера, начиная с самого большого, выбираются представители\n",
    "\n",
    "Для генерации тестовых данных используется отдельная небольшая специально обученная модель\n",
    "\n",
    "### Результаты\n",
    "\n",
    "![Results](./res/05_alphacode_results.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Упражнение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Провести эксперимент с генерацей кода с помощью модели InCoder. Исследовать влияние описания задачи, наличия юнит-тестов и т.д. на качество сгенерированного кода."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Полезные ссылки\n",
    "\n",
    "- https://github.com/saltudelft/ml4se#code-generation\n",
    "- [GPT-3](https://jalammar.github.io/how-gpt3-works-visualizations-animations/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
