{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. LARGE PL MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [x] введение\n",
    "2. [x] CoTexT\n",
    "3. [x] упражнение\n",
    "4. [x] ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Введение\n",
    "\n",
    "Отдельная модель под каждую задачу --- это хорошо. Тем не менее, иногда хочется иметь одну модель, которая умеет решать разные задачи:\n",
    "- одну модель поддерживать проще, чем несколько (правда, если она не слишком большая)\n",
    "- одна модель, обученная сразу под несколько задач, может справляться с задачами лучше, чем модели, обученные под каждую из задач в отдельности. Особенно это актуально, если задачи похожи\n",
    "\n",
    "Multi-task learning --- обучение модели машинного обучения нескольким задачам одновременно. При этом, задачи не должны быть слишком похожими и не слишком различными. Как результат, возможно улучшение обобщающих способностей модели.\n",
    "\n",
    "![](./res/13_multi-task.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. CoTexT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Phan et al - CoTexT: Multi-task Learning with Code-Text Transformer](https://aclanthology.org/2021.nlp4prog-1.5/) [@NLP4Prog 2021]\n",
    "\n",
    "**Co**de and **Tex**t **T**ransfer Transformer)\n",
    "\n",
    "- Transformer-based encoder-decoder\n",
    "- NL-PL задачи:\n",
    "    - суммаризация кода\n",
    "    - генерация кода\n",
    "    - детекция дефектов\n",
    "    - исправление ошибок в коде\n",
    "- языки: Java, Python, Javascript, PHP, Ruby etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Модель\n",
    "\n",
    "В основе лежит модель T5 --- **T**ext-**t**o-**T**ext **T**ransfer **T**ransformer ([Raffel et al., 2019](https://arxiv.org/abs/1910.10683)).\n",
    "\n",
    "![](./res/13_t5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Токенизация\n",
    "\n",
    "Для токенизации используется [Sentence Piece Unsupervised Text Tokenizer](https://github.com/google/sentencepiece). В отличие от BPE пробелы тоже включаются в список символов, используемых в процессе токенизации. Однако специальные токены, используемые в коде (например, `[`, `{`, `$` и т. д.) не используются в модели Sentence Piece, но важный в языках программирования. Поэтому эти символы кодируются на естественном языке.\n",
    "- фиксированный размер словаря\n",
    "- не требует предварительного разбиения на части\n",
    "- пробелы и специальный символы сохраняются, возможна детокенизация: `detokenized = ''.join(pieces).replace('▁', ' ')`\n",
    "    - `<` -> `SMALLER_TOKEN`\n",
    "    - `>` -> `GREATER_TOKEN`\n",
    "    - `{` -> `OPEN_CURLY_TOKEN`\n",
    "    - `}` -> `CLOSE_CURLY_TOKEN`\n",
    "    - `[` -> `OPEN_SQUARE_TOKEN`\n",
    "    - `]` -> `CLOSE_SQUARE_TOKEN`\n",
    "    - `^` -> `EXPONENTIAL_TOKEN`\n",
    "    - `#` -> `SHARP_TOKEN`\n",
    "    - `$` -> `DOLLAR_TOKEN`    \n",
    "    - `'` -> `UNK_TOKEN`    \n",
    "    - `\\n` -> `NEW_LINE_TOKEN`    \n",
    "    - `\\t` -> `INDENT`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Обучение\n",
    "\n",
    "Данные:\n",
    "- унимодальные данные (NL, PL)\n",
    "- бимодальные данные (NL-PL)\n",
    "\n",
    "Датасеты:\n",
    "- [CodeSearchNet Corpus Collection](https://github.com/github/CodeSearchNet)\n",
    "- [GitHub Repositories](https://console.cloud.google.com/marketplace/details/github/github-repos)\n",
    "\n",
    "![](./res/13_cotext_pre-training.png)\n",
    "\n",
    "Была использована модель [T5](https://huggingface.co/docs/transformers/model_doc/t5)-Base, обученная на [C4](https://commoncrawl.org/).\n",
    "Все данные в текстовом формате (text-to-text). Тест и код конкатенируются в единую последовательность.\n",
    "На этапе обучения в self-supervised режиме части последовательностей (span) случайно маскируются.\n",
    "\n",
    "![](./res/13_cotext_fill-in-the-blank.png)\n",
    "\n",
    "- 220M параметров\n",
    "- lr = 0.001\n",
    "- 1024 --- длина входной и выходной последовательностей\n",
    "- TPU v2-8 on Google Colab\n",
    "- batch_size = 128\n",
    "- model parallelism = 2\n",
    "\n",
    "#### CodeSearchNet Corpus Collection\n",
    "\n",
    "- функции + описание на естественном языке\n",
    "- GitHub\n",
    "- Python, Java, Javascript, PHP, Ruby, Go\n",
    "\n",
    "#### GitHub repositories\n",
    "\n",
    "- функции + описание на естественном языке\n",
    "- GitHub (Google BigQuery)\n",
    "- Java, Python\n",
    "\n",
    "### Multi-task\n",
    "\n",
    "Обучение проходило единоообразно (максимальное правдоподобие) независимо от задач текст-код или код-текст. \n",
    "Для указания решаемой задачи использовался префикс (к входной последовательности).\n",
    "Например, при файнтюнинге задачи CodeSummarization для каждого языка программирования добавляется префикс (язык программирования, например, Java) к входной последовательности.\n",
    "\n",
    "![](./res/13_cotext_multi-task.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Evaluation\n",
    "\n",
    "### CodeXGLUE\n",
    "\n",
    "Использовался бенчмарк [CodeXGLUE](https://microsoft.github.io/CodeXGLUE/) (General Language Understanding Evaluation benchmark for CODE).\n",
    "- набор задач анализа кода (10 задач, включая сценарии код-текст, текст-код, код-код и текст-текст)\n",
    "- платформа для оценки модели\n",
    "- таблица лидеров для сравнения\n",
    "\n",
    "![](./res/13_cotext_datasets.png)\n",
    "\n",
    "Оценивание происходило на задачах:\n",
    "- Code Summarization\n",
    "- Code Refinement\n",
    "\n",
    "### Используемые длины последовательностей\n",
    "\n",
    "![](./res/13_cotext_input_target.png)\n",
    "\n",
    "### Code Summarization\n",
    "\n",
    "Описать код на естественном языке. \n",
    "- CodeSearchNet\n",
    "- Python, Java, Javascript, PHP, Ruby, Go\n",
    "\n",
    "### Code Generation\n",
    "\n",
    "Генерация кода по описанию\n",
    "- CONCODE dataset\n",
    "- Java\n",
    "\n",
    "### Code Refinement (or Code Repair)\n",
    "\n",
    "Исправление ошибок в коде.\n",
    "- Bug2Fix corpus\n",
    "- Java\n",
    "- 50--100 токенов\n",
    "\n",
    "### Defect Detection\n",
    "\n",
    "Содержит ли код уязвимости или нет.\n",
    "- Devign dataset\n",
    "- C\n",
    "\n",
    "### Метрики\n",
    "\n",
    "- BLEU\n",
    "- CodeBLEU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Результаты\n",
    "\n",
    "Сравнение происходило с\n",
    "- CodeGPT (GPT-2, CodeSearchNet dataset)\n",
    "- CodeBERT (RoBERTa)\n",
    "- PLBART (BART)\n",
    "\n",
    "### Code Summarization\n",
    "\n",
    "![](./res/13_cotext_code_summarization.png)\n",
    "\n",
    "### Code Refinement\n",
    "\n",
    "![](./res/13_cotext_code_refinement.png)\n",
    "\n",
    "### Code Generation\n",
    "\n",
    "![](./res/13_cotext_code_generation.png)\n",
    "\n",
    "### Defect Prediction\n",
    "\n",
    "![](./res/13_cotext_defect_prediction.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Реализация\n",
    "\n",
    "- [модели](https://console.cloud.google.com/storage/browser/cotext)\n",
    "- github: [justinphan3110/CoTexT](https://github.com/justinphan3110/CoTexT)\n",
    "- huggingface: [razent/cotext-1-ccg](https://huggingface.co/razent/cotext-1-ccg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('razent/cotext-1-ccg')\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('razent/cotext-1-ccg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_id = 'cpu'\n",
    "\n",
    "sentence = 'def add(a, b): return a + b'\n",
    "text = f'python: {sentence} </s>'\n",
    "\n",
    "encoding = tokenizer.encode_plus(text, pad_to_max_length=True, return_tensors='pt')\n",
    "input_ids, attention_masks = encoding['input_ids'].to(device_id), encoding['attention_mask'].to(device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(\n",
    "    input_ids=input_ids, attention_mask=attention_masks,\n",
    "    max_length=256,\n",
    "    early_stopping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for output in outputs:\n",
    "    line = tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Упражнение\n",
    "\n",
    "Провести исследование применимости модели CoTexT для создания документации (Code Summarization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Ссылки\n",
    "\n",
    "- [Phan et al - CoTexT: Multi-task Learning with Code-Text Transformer](https://aclanthology.org/2021.nlp4prog-1.5/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
