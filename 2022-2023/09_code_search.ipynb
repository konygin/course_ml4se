{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09. CODE SEARCH: TWO-STAGE PARADIGM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [x] введение\n",
    "2. [x] TOSS\n",
    "3. [x] evaluation\n",
    "4. [x] результаты\n",
    "5. [x] ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Введение\n",
    "\n",
    "Существующие подходы поиска по коду условно можно разделить на две группы:\n",
    "1. методы на основе Information retrieval: они часто работают быстро, но иногда не совсем точны\n",
    "2. методы на основе DL: могут показывать высокое качество, но обычно более медленные из-за использования больших моделей.\n",
    "\n",
    "Среди DL-подходов, в свою очередь, можно выделить *биэнкодерные (bi-encoder)* и *кроссэнкодерные (cross-encoder)* решения.\n",
    "\n",
    "## 1. Биэнкодерный подход\n",
    "\n",
    "В биэнкодерном подходе входные данные (текстовый запрос, код) независимо вкладываются в векторное пространство.\n",
    "\n",
    "![](./res/09_bi-encoder.png)\n",
    "\n",
    "Таким образом, эмбеддинги для кода могут быть вычислены заранее, что ускоряет работу поиска.\n",
    "\n",
    "## 2. Кроссэнкодерный подход\n",
    "\n",
    "В отличие от бинэнкодеров в случае кроссэнкодера механизм эттеншна выполняется на паре запрос-код, таким образом  происходит взаимодействие информации на естественном языке с информацие на языке программирования в процессе векторизации.\n",
    "\n",
    "![](./res/09_cross-encoder.png)\n",
    "\n",
    "За счёт этого кроссэнкодерные подходы могут достичь более высокую точность, чем биэнкодерные решения.\n",
    "Но кроссэнкодерные подходы не могут создавать отдельные эмбеддинги для коды, необхожимые для многих приложений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. TOSS\n",
    "\n",
    "Как объединить преимущества всех походов?\n",
    "\n",
    "![](./res/09_toss_paper.png)\n",
    "\n",
    "В работе [Revisiting Code Search in a Two-Stage Paradigm](https://arxiv.org/abs/2208.11274) авторы предложили\n",
    "TOSS (TwO-Stage fuSion code Search framework) --- двухэтапный фреймворк для поиска по коду, который сочетает в себе преимущества различных методов поиска кода.\n",
    "TOSS сначала использует модели на основе Information Retrieval и биэнкодерные модели для эффективного поиска небольшого количества лучших кандидатов, а затем использует кроссэнкодеры для более точного ранжирования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Обозначения и вспомогательные понятия\n",
    "\n",
    "Пусть\n",
    "- $q$ --- поисковый запрос\n",
    "- $C$ --- корпус кода (где происходит поиск)\n",
    "- $M(\\cdot, \\cdot)$ --- функция соответствия (match) сниппета кода $c$ поисковому запросу $q$, чем больше значение фунции $M$, тем лучше $c$ соответствует $q$.\n",
    "\n",
    "Тогда поиск по коду --- это поиск такого $c$ для запроса $q$, что значение $M(c, q)$ максимально:\n",
    "$$max_{c \\in C}M(c, q).$$\n",
    "\n",
    "#### Биэнкодерный подход\n",
    "\n",
    "Пусть $c \\in C$ --- сниппет кода из корпуса $C$.\n",
    "Пусть $\\Gamma'$ и $\\Gamma''$ --- энкодеры для запросов и сниппетов кода, соответственно.\n",
    "Тогда через $e_q$ и $e_c$ обозначим эмбеддинги для $q$ и $c$:\n",
    "$$e_q = \\Gamma'(q)$$\n",
    "$$e_c = \\Gamma''(c).$$\n",
    "Кроме того, нам необходима некоторая функция похожести или функция расстояния $s_{bi}$ для векторов.\n",
    "Например, косинус угла между векторами или евклидово расстояние:\n",
    "$$s_{bi}: (e_q, e_c) \\mapsto R.$$\n",
    "\n",
    "Таким образом, имеем $$M_{bi}(\\cdot, \\cdot) = s_{bi}(\\Gamma'(\\cdot), \\Gamma''(\\cdot)).$$\n",
    "\n",
    "Энкодеры $\\Gamma'$ и $\\Gamma''$ --- нейронные сети, предварительно обученные на парах (текст, код).\n",
    "\n",
    "#### Кроссэнкодерный подход\n",
    "\n",
    "В этом подхоже поисковый запрос и сниппет кода объединяются (конкатенируются через специальный токен $<SEP>$) и являются входом для модели $\\Gamma$, которая вычисляет кроссмодальную похожесть (энкодер+регрессия):\n",
    "\n",
    "$$M_{cr}(\\cdot, \\cdot) = \\Gamma([q, <SEP>, c]).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Двухэтапный поиск по коду\n",
    "\n",
    "1. Сначала находим набор сниппетов-кандидатов на основе функции $M_{recall}$.\n",
    "2. Затем ранжируем набор кандидатов на основе функции $M_{rank}$.\n",
    "\n",
    "![](./res/09_toss_overview.png)\n",
    "\n",
    "Если одна модель на первом этапе.\n",
    "\n",
    "1. $C_{sub} = \\arg \\max_{C' \\subset C, |C'| = K} \\sum_{c \\in C'} M_{recall}(c, q)$ --- набор из $K$ кандидатов.\n",
    "\n",
    "Функция $M_{recall}$ должна быть быстрой, но, возможно, неточной.\n",
    "\n",
    "2. $c_{*}   = \\arg \\max_{c \\in C_{sub}}                          M_{rank  }(c, q)$ --- итоговый сниппет.\n",
    "\n",
    "Функци я $M_{rank}$ может быть сложной.\n",
    "\n",
    "\n",
    "Кроме того, первый этап ($M_{recall}$) может включать несколько $m$ различных способов поиска по коду. Полученные кандидаты объединяются и отправляются на второй этап:\n",
    "\n",
    "$$C^{i}_{sub} = \\arg \\max_{C' \\subset C, |C'| = K} \\sum_{c \\in C'} M^i_{recall}(c, q), \\,\\,\\, 1 \\leq i \\leq m$$\n",
    "$$C_{all} = \\cup_{1 \\leq i \\leq m}C^i_{sub}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluation\n",
    "\n",
    "Как оценить качество?\n",
    "\n",
    "## 3.1 Датасет\n",
    "\n",
    "- [CodeSearchNet](https://github.com/github/CodeSearchNet) --- 14919 запросов и 43827 кандидатов\n",
    "\n",
    "## 3.2 Модели\n",
    "\n",
    "Требования к выбору моделей:\n",
    "- исходный код опубликован\n",
    "- модели работают со всеми шестью языками программирования из CodeSearchNet\n",
    "- исследовательская статья прошла рецензирование\n",
    "\n",
    "В результате следующие модели были выбраны:\n",
    "- на основе Information retrieval\n",
    "  - [Jaccard](https://www.scienceopen.com/document?vid=01a9bb0e-a14c-461f-85c9-f407259515dc): был использован метод `jaccard_score` из библиотеки `sklearn`\n",
    "  - [BOW](https://nlp.stanford.edu/IR-book/information-retrieval-book.html): был использовае `CountVectorizer` для векторизации из библиотеки `sklearn`, кроссмодальная похожесть оценивалась через косинус угла между векторами\n",
    "  - [TFIDF](https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/asi.4630270302): был использован `TfidfVectorizer` из библиотеки `sklearn` на основе TFIDF-признаков, кроссмодальная похожесть оценивалась через косинус угла между векторами\n",
    "  - [BM25](https://www.nowpublishers.com/article/Details/INR-019): был использован Python-пакет `Rank-BM25`\n",
    "- биэнкодерные\n",
    "  - [CODEnn](https://github.com/guxd/deep-code-search): на основе LSTM\n",
    "  - [GraphCodeBERT](https://github.com/microsoft/CodeBERT/tree/master/GraphCodeBERT/codesearch)\n",
    "  - [CodeBERT-bi](https://arxiv.org/abs/2002.08155): вариант CodeBERT, описан в Приложении; модель сначала кодирует запрос и код раздельно, а затем вычисляет сходство через скалярное произведение\n",
    "- кроссэнкодерные\n",
    "  - [CodeBERT](https://github.com/microsoft/CodeBERT)\n",
    "  - [CoCLR](https://github.com/Jun-jie-Huang/CoCLR): метод constrastive learning на основе CodeBERT\n",
    "  \n",
    "  \n",
    " ## 3.3 Метрики\n",
    " \n",
    " ### MRR\n",
    " \n",
    "MRR (Mean Reciprocal Ranking) --- статистическая оценка откликов процесса на запросы, упорядоченных по вероятности и правильности. Характеризует эффективность информационного поиска.\n",
    "MRR определяется как среднее обратных рангов по всем запросам $q$ из $Q$:\n",
    "\n",
    "$$MRR = \\frac{1}{|Q|} \\sum_{q \\in Q} \\frac{1}{rank(q)},$$\n",
    "\n",
    "где $rank(q)$ означает положение первого релевантного документа для запроса $q$.\n",
    " \n",
    " ### R@K\n",
    " \n",
    "R@K (K=1, 5, 10, 100, 1000) --- количество раз, когда корректный ответ попал в топ-K ответов на запрос."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Результаты\n",
    "\n",
    "## 4.1 Предобработка\n",
    "\n",
    "![](./res/09_preprocessing.png)\n",
    "\n",
    "- SPS: разбить слова согласно написанию в стиле pascal или snake case, например, `TwoStageMethod` преваращется в  `Two Stage Method”`\n",
    "- DS: удалить английские стоп-слова, например, `both`, `more`, `some` и т.д.\n",
    "- RS: Ronin Split, например, преобразовать `showtraceback` в `show trace back`\n",
    "- POS: Part-of-speech restoration, лемматицзация, например, `configs` в `config`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Baselines\n",
    "\n",
    "BM25 --- поисковая функция на неупорядоченном множестве термов (\"мешке слов\") и множестве документов, которые она оценивает на основе встречаемости слов запроса в каждом документе, без учёта взаимоотношений между ними (например, близости).\n",
    "\n",
    "![](./res/09_baselines.png)\n",
    "\n",
    "- DL-подходы дают более высокое качество\n",
    "- лучше всех кроссэнкодерный подход на основе CodeBERT\n",
    "- кросс-энкодерные подходы медленные\n",
    "\n",
    "![](./res/09_baselines_viz.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Качество\n",
    "\n",
    "![](./res/09_toss_results.png)\n",
    "\n",
    "- TOSS улучшает качество\n",
    "- Подход [GraphCodeBERT + BM25] + CodeBERT работает лучше всех\n",
    "\n",
    "![](./res/09_toss_langs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Скорость\n",
    "\n",
    "![](./res/09_toss_perfomance.png)\n",
    "![](./res/09_toss_speed.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Полезные ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Birillo et al - Reflekt A library for compile-time reflection in Kotlin 2022\n",
    "- Chai et al - Cross-domain deep code search with few-shot meta learning 2022\n",
    "- Cheng Kuang - CSRS Code search with relevance matching and semantic matching 2022\n",
    "- Eberhart McMillan - Generating clarifying questions for query refinement in source code search 2022\n",
    "- Grazia et al - DiffSearch A scalable and precise search engine for code changes 2022\n",
    "- Gu et al - Accelerating code search with deep hashing and code classification 2022\n",
    "- Gu et al - Multimodal representation for neural code search 2022\n",
    "- Haldar et al - A multi-perspective architecture for semantic code search 2021\n",
    "- [Hu et al - Revisiting code search in a two-stage paradigm 2022](https://arxiv.org/abs/2208.11274)\n",
    "- Li et al - CodeRetriever Unimodal and bimodal contrastive learning for code search 2022\n",
    "- Liu et al - CodeMatcher Searching code based on sequential semantics of important query words 2022\n",
    "- Liu et al - GraphSearchNet Enhancing GNNs via capturing global dependency for semantic code search 2022\n",
    "- Shi et al - Enhancing semantic code search with multimodal contrastive learning and soft data augmentation 2022\n",
    "- Shuai et al - Improving code search with co-attentive representation learning 2020\n",
    "- Sun et al - Code search based on context-aware code translation 2022\n",
    "- Sun et al - On the importance of building high-quality training datasets for neural code search 2022\n",
    "- Villmow et al - Addressing leakage in self-supervised contextualized code retrieval 2022\n",
    "- Wang et al - Enriching query semantics for code search with reinforcement learning 2021\n",
    "- Yan et al - Are the code snippets what we are searching for A benchmark and an empirical study on code search with natural-language queries 2020\n",
    "- Zhang et al - Bag-of-words baselines for semantic code search 2021\n",
    "- https://ieeexplore.ieee.org/abstract/document/8453172\n",
    "- https://dl.acm.org/doi/abs/10.1145/2393596.2393606\n",
    "- https://ieeexplore.ieee.org/abstract/document/6606630"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
