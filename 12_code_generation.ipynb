{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. CODE GENERATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Introduction\n",
    "2. HumanEval\n",
    "3. Generation with LLMs\n",
    "4. Generation with Agents\n",
    "5. Context-aware generation\n",
    "7. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PROBLEM\n",
    "\n",
    "- Input: documentation (+ unit tests)\n",
    "- Output: code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATASETS\n",
    "\n",
    "- [HumanEval](https://arxiv.org/abs/2107.03374): [164 programming problems](https://huggingface.co/datasets/openai_humaneval)\n",
    "- [MBPP](https://arxiv.org/abs/2108.07732): The Mostly Basic Programming Problem, [974 programming problems](https://huggingface.co/datasets/mbpp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### METRICS\n",
    "\n",
    "![](res/12_metrics.png)\n",
    "\n",
    "Source: [Li et al - The Metric for Automatic Code Generation](https://www.sciencedirect.com/science/article/pii/S1877050920302210)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metric `pass@k`**\n",
    "\n",
    "1. Generate $k$ code samples per problem.\n",
    "2. A problem is considered solved if any sample passes the unit tests, and the total fraction of problems solved is reported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. HumanEval\n",
    "\n",
    "- paper: [Evaluating Large Language Models Trained on Code](https://arxiv.org/abs/2107.03374)\n",
    "- github: [openai/human-eval](https://github.com/openai/human-eval)\n",
    "- dataset: [openai_humaneval](https://huggingface.co/datasets/openai_humaneval)\n",
    "- leaderboard: [Code Generation on HumanEval](https://paperswithcode.com/sota/code-generation-on-humaneval)\n",
    "- [Big Code Models Leaderboard](https://huggingface.co/spaces/bigcode/bigcode-models-leaderboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HumanEval:\n",
    "- 164 задачи\n",
    "- задача: сигнатура функции, строка документации, тело и несколько тестов (в среднем, 7.7 тестов на задачу)\n",
    "- задачи написаны заново, чтобы не было пересечения с GitHub: например, существует более десяти общедоступных репозиториев, содержащих решения задач [Codeforces](https://codeforces.com/)\n",
    "- задачи программирования в наборе данных HumanEval оценивают понимание языка, рассуждения, алгоритмы и простую математику\n",
    "\n",
    "Корректность оценивается с помощью метрики `pass@k`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Примеры\n",
    "\n",
    "- белый фон: отправляем в модель\n",
    "- жёлтый фон: результат генерации\n",
    "\n",
    "![Prompt](https://production-media.paperswithcode.com/datasets/a2af6cf1-212b-4a05-8d5c-55170a21ce05.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generation with LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Easy with HuggingFace\n",
    "\n",
    "```\n",
    "from transformers import pipeline\n",
    "pipe = pipeline('text-generation', model='lvwerra/codeparrot')\n",
    "\n",
    "text = 'def add_numbers(a, b):\\n    \"\"\"add two numbers\"\"\"'\n",
    "code = pipe(text)[0]['generated_text']\n",
    "\n",
    "print(code)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Models\n",
    "\n",
    "![](res/12_code_models.png)\n",
    "\n",
    "[Source](https://arxiv.org/abs/2311.10372)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HumanEval Leadeboard\n",
    "\n",
    "![](res/12_humaneval_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](res/12_humaneval_2.png)\n",
    "\n",
    "[Source](https://arxiv.org/abs/2311.10372)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MBPP Leaderboard\n",
    "\n",
    "![](res/12_mbpp_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](res/12_mbpp_2.png)\n",
    "\n",
    "[Source](https://arxiv.org/abs/2311.10372)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Generation with Agents\n",
    "\n",
    "\n",
    "![](res/12_humaneval_agents.png)\n",
    "\n",
    "Source: [Code Generation on HumanEval](https://paperswithcode.com/sota/code-generation-on-humaneval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Rank | Model | Pass@1  | Source | Year| \n",
    "|---:|-------------------------------------------------------|-------|--------------------------------------------------------------------------------------------------------|-----:|\n",
    "|  1 | AgentCoder  (GPT-4)                                   | 96.3  | AgentCoder: Multi-Agent-based Code Generation with Iterative Testing and Optimisation                  | 2023 |\n",
    "|  2 | LDB  (GPT-3.5, based on seed programs from Reflexion) | 95.1  | LDB: A Large Language Model Debugger via Verifying Runtime Execution Step-by-step                      | 2024 |\n",
    "|  3 | Language Agent Tree Search  (GPT-4)                   | 94.4  | Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models                    | 2023 |\n",
    "|  4 | L2MAC  (GPT-4)                                        | 90.2  | L2MAC: Large Language Model Automatic Computer for Extensive Code Generation                           | 2023 |\n",
    "|  5 | OctorCoder  (GPT-4)                                   | 86.6  | OctoPack: Instruction Tuning Code Large Language Models                                                | 2023 |\n",
    "|  6 | ANPL  (GPT-4)                                         | 86.6  | ANPL: Towards Natural Programming with Interactive Decomposition                                       | 2023 |\n",
    "|  7 | MetaGPT  (GPT-4)                                      | 85.9  | MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework                                    | 2023 |\n",
    "|  8 | Parsel  (GPT-4 + CodeT)                               | 85.1  | Parsel: Algorithmic Reasoning with Language Models by Composing Decompositions                         | 2022 |\n",
    "|  9 | Claude 3 Opus  (0-shot)                               | 84.9  | The Claude 3 Model Family: Opus, Sonnet, Haiku                                                         | 2024 |\n",
    "| 10 | Language Agent Tree Search  (GPT-3.5)                 | 83.8  | Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models                    | 2023 |\n",
    "| 11 | AgentCoder  (ChatGPT)                                 | 79.9  | AgentCoder: Multi-Agent-based Code Generation with Iterative Testing and Optimisation                  | 2023 |\n",
    "| 12 | LLMCodeGen Scrum  (GPT-3.5 + zero-shot)               | 78.5  | When LLM-based Code Generation Meets the Software Development Process                                  | 2024 |\n",
    "| 13 | GPT-4  (0-shot)                                       | 76.5  | DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence       | 2024 |\n",
    "| 14 | ANPL  (GPT-3.5)                                       | 76.2  | ANPL: Towards Natural Programming with Interactive Decomposition                                       | 2023 |\n",
    "| 15 | Claude 3 Haiku  (0-shot)                              | 75.9  | The Claude 3 Model Family: Opus, Sonnet, Haiku                                                         | 2024 |\n",
    "| 16 | INTERVENOR  (GPT-3.5)                                 | 75.6  | INTERVENOR: Prompting the Coding Ability of Large Language Models with the Interactive Chain of Repair | 2023 |\n",
    "| 17 | SRank  (WizardCoder)                                  | 75.31 | Neural Code Generation Enhancement via Functional Overlap Reranking                                    | 2023 |\n",
    "| 18 | Gemini Ultra  (0-shot)                                | 74.4  | Gemini: A Family of Highly Capable Multimodal Models                                                   | 2023 |\n",
    "| 19 | Claude 3 Sonnet  (0-shot)                             |    73 | The Claude 3 Model Family: Opus, Sonnet, Haiku                                                         | 2024 |\n",
    "| 20 | Gemini 1.5 Pro  (0-shot)                              | 71.9  | Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context                    | 2024 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More:\n",
    "- [Collaborative Agents](09_collaborative_agents.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Context-aware generation\n",
    "\n",
    "- fine-tuning\n",
    "- in-context learning\n",
    "- RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAG (Retrieval-Augmented Generation)\n",
    "\n",
    "![](res/12_naive_rag.png)\n",
    "\n",
    "Source: [Gao et al - Retrieval-Augmented Generation for Large Language Models A Survey 2024](https://arxiv.org/abs/2312.10997)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing\n",
    "\n",
    "1. cleaning and extraction of raw data in diverse formats\n",
    "2. converting into a uniform plain text format\n",
    "3. text is segmented into smaller chunks\n",
    "4. chunks are then encoded into vector representations using an embedding model\n",
    "5. embeddings are stored in vector database\n",
    "\n",
    "This step is crucial for enabling efficient similarity searches in the subsequent retrieval phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieval\n",
    "\n",
    "1. transform the query into a vector representation (the same encoding model utilized during the indexing phase)\n",
    "2. compute the similarity scores between the query vector and the vector of chunks within the indexed corpus.\n",
    "3. prioritize and retrieve the top-$K$ chunks that demonstrate the greatest similarity to the query\n",
    "\n",
    "The retrieval phase often struggles with precision and recall, leading to the selection of misaligned or irrelevant chunks, and the missing of crucial information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generation\n",
    "\n",
    "- chunks are subsequently used as the expanded context in prompt\n",
    "\n",
    "In generating responses, the model may face the issue of hallucination, where it produces content not supported by the retrieved context. This phase can also suffer from irrelevance, toxicity, or bias in the outputs, detracting from the quality and reliability of the responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advanced RAG\n",
    "\n",
    "![](res/12_naive_advanced_modular_rag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAG or Fine-Tuning\n",
    "\n",
    "![](res/12_rag_vs_all.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAG for Code Generation\n",
    "\n",
    "The diagram below shows a high-level RAG pattern for code generation with Codey APIs.\n",
    "\n",
    "![](res/12_context-aware_code_generation_rag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Identify source information: API definition, code repositories, documentation, or similar.\n",
    "2. Determine the chunking scheme: methods that respect natural code boundaries, such as function, class, or module borders; techniques like random splits or mid-sentence/clauses could break the context and degrade the output.\n",
    "3. Generate embeddings and index them in a vector database: when a query is received, another embedding is generated for the query and used to help retrieve relevant information chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More:\n",
    "- [Context-aware code generation: Retrieval augmentation and Vertex AI Codey APIs](https://cloud.google.com/blog/products/ai-machine-learning/context-aware-code-generation-rag-and-vertex-ai-codey-apis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. References\n",
    "\n",
    "- https://arxiv.org/abs/2107.03374\n",
    "- https://arxiv.org/abs/2208.03133\n",
    "- https://arxiv.org/abs/2311.10372\n",
    "- https://arxiv.org/abs/2401.15940\n",
    "- [Gao et al - Retrieval-Augmented Generation for Large Language Models A Survey 2024](https://arxiv.org/abs/2312.10997)\n",
    "- [Zhao et al - Retrieval-Augmented Generation for AI-Generated Content A Survey 2024](https://arxiv.org/abs/2402.19473)\n",
    "- [Yu et al - Evaluation of Retrieval-Augmented Generation A Survey 2024](https://arxiv.org/abs/2405.07437)\n",
    "- https://github.com/saltudelft/ml4se?tab=readme-ov-file#code-generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
